{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning BERT for Segment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "excel_file = './Segment_Training_Data.xlsx'\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "descriptions = df['Descriptions'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Tokenization of Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tokenized_texts = tokenizer(descriptions, truncation=True, padding=True)\n",
    "\n",
    "combined_texts = [{'input_ids': input_ids, 'attention_mask': attention_mask} \n",
    "                  for input_ids, attention_mask in zip(tokenized_texts['input_ids'], tokenized_texts['attention_mask'])]\n",
    "\n",
    "labels = list(df['Segment'])\n",
    "\n",
    "label_map = {label: idx for idx, label in enumerate(set(labels))}\n",
    "labels = [label_map[label] for label in labels]\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(combined_texts, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'input_ids': torch.tensor(self.encodings[idx]['input_ids'], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(self.encodings[idx]['attention_mask'], dtype=torch.long),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = CustomDataset(train_texts, train_labels)\n",
    "val_dataset = CustomDataset(val_texts, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setup and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Training batch 1 last loss: 0.16910549998283386\n",
      "Training batch 2 last loss: 0.17150622606277466\n",
      "Training batch 3 last loss: 0.16997678577899933\n",
      "Training batch 4 last loss: 0.16934025287628174\n",
      "Training batch 5 last loss: 0.17853830754756927\n",
      "Training batch 6 last loss: 0.1740284264087677\n",
      "Training batch 7 last loss: 0.16648337244987488\n",
      "Training batch 8 last loss: 0.1677701473236084\n",
      "Training batch 9 last loss: 0.16746731102466583\n",
      "Training batch 10 last loss: 0.170078307390213\n",
      "Training batch 11 last loss: 0.1666891872882843\n",
      "Training batch 12 last loss: 0.1678897887468338\n",
      "Training batch 13 last loss: 0.15756487846374512\n",
      "Training batch 14 last loss: 0.16864967346191406\n",
      "Training batch 15 last loss: 0.17581261694431305\n",
      "Training batch 16 last loss: 0.1568889170885086\n",
      "Training batch 17 last loss: 0.16459132730960846\n",
      "\n",
      "Training epoch 1 loss:  0.16459132730960846\n",
      "Epoch 1, Validation Loss: 2.6553704261779787, Validation Accuracy: 10.44776119402985%\n",
      "Epoch:  2\n",
      "Training batch 1 last loss: 0.16332721710205078\n",
      "Training batch 2 last loss: 0.16116103529930115\n",
      "Training batch 3 last loss: 0.17238594591617584\n",
      "Training batch 4 last loss: 0.15394164621829987\n",
      "Training batch 5 last loss: 0.15982550382614136\n",
      "Training batch 6 last loss: 0.159730464220047\n",
      "Training batch 7 last loss: 0.16358055174350739\n",
      "Training batch 8 last loss: 0.15404433012008667\n",
      "Training batch 9 last loss: 0.15485931932926178\n",
      "Training batch 10 last loss: 0.15175794064998627\n",
      "Training batch 11 last loss: 0.1489650011062622\n",
      "Training batch 12 last loss: 0.15117907524108887\n",
      "Training batch 13 last loss: 0.15437258780002594\n",
      "Training batch 14 last loss: 0.14886941015720367\n",
      "Training batch 15 last loss: 0.15336908400058746\n",
      "Training batch 16 last loss: 0.14239387214183807\n",
      "Training batch 17 last loss: 0.1456695795059204\n",
      "\n",
      "Training epoch 2 loss:  0.1456695795059204\n",
      "Epoch 2, Validation Loss: 2.3566123485565185, Validation Accuracy: 46.26865671641791%\n",
      "Epoch:  3\n",
      "Training batch 1 last loss: 0.1418747901916504\n",
      "Training batch 2 last loss: 0.14575134217739105\n",
      "Training batch 3 last loss: 0.14890868961811066\n",
      "Training batch 4 last loss: 0.14227519929409027\n",
      "Training batch 5 last loss: 0.14617294073104858\n",
      "Training batch 6 last loss: 0.13914433121681213\n",
      "Training batch 7 last loss: 0.14778950810432434\n",
      "Training batch 8 last loss: 0.13161778450012207\n",
      "Training batch 9 last loss: 0.13961462676525116\n",
      "Training batch 10 last loss: 0.13909608125686646\n",
      "Training batch 11 last loss: 0.13905784487724304\n",
      "Training batch 12 last loss: 0.13685578107833862\n",
      "Training batch 13 last loss: 0.1248905286192894\n",
      "Training batch 14 last loss: 0.12973271310329437\n",
      "Training batch 15 last loss: 0.1335705667734146\n",
      "Training batch 16 last loss: 0.135010227560997\n",
      "Training batch 17 last loss: 0.13108360767364502\n",
      "\n",
      "Training epoch 3 loss:  0.13108360767364502\n",
      "Epoch 3, Validation Loss: 2.079541826248169, Validation Accuracy: 52.23880597014925%\n",
      "Epoch:  4\n",
      "Training batch 1 last loss: 0.1251988410949707\n",
      "Training batch 2 last loss: 0.13026130199432373\n",
      "Training batch 3 last loss: 0.14289472997188568\n",
      "Training batch 4 last loss: 0.12245737016201019\n",
      "Training batch 5 last loss: 0.11929412186145782\n",
      "Training batch 6 last loss: 0.11858320236206055\n",
      "Training batch 7 last loss: 0.11585509777069092\n",
      "Training batch 8 last loss: 0.12598775327205658\n",
      "Training batch 9 last loss: 0.12004129588603973\n",
      "Training batch 10 last loss: 0.12064177542924881\n",
      "Training batch 11 last loss: 0.1077430322766304\n",
      "Training batch 12 last loss: 0.11209036409854889\n",
      "Training batch 13 last loss: 0.11831142753362656\n",
      "Training batch 14 last loss: 0.11594409495592117\n",
      "Training batch 15 last loss: 0.11511186510324478\n",
      "Training batch 16 last loss: 0.10164123773574829\n",
      "Training batch 17 last loss: 0.14050042629241943\n",
      "\n",
      "Training epoch 4 loss:  0.14050042629241943\n",
      "Epoch 4, Validation Loss: 1.787955641746521, Validation Accuracy: 73.13432835820896%\n",
      "Epoch:  5\n",
      "Training batch 1 last loss: 0.10419882088899612\n",
      "Training batch 2 last loss: 0.10887641459703445\n",
      "Training batch 3 last loss: 0.10839037597179413\n",
      "Training batch 4 last loss: 0.11948999762535095\n",
      "Training batch 5 last loss: 0.10518421232700348\n",
      "Training batch 6 last loss: 0.09447428584098816\n",
      "Training batch 7 last loss: 0.10276606678962708\n",
      "Training batch 8 last loss: 0.09451619535684586\n",
      "Training batch 9 last loss: 0.09253013879060745\n",
      "Training batch 10 last loss: 0.10824339836835861\n",
      "Training batch 11 last loss: 0.09659527987241745\n",
      "Training batch 12 last loss: 0.10099253058433533\n",
      "Training batch 13 last loss: 0.10727293789386749\n",
      "Training batch 14 last loss: 0.09952355176210403\n",
      "Training batch 15 last loss: 0.08843138068914413\n",
      "Training batch 16 last loss: 0.09556932002305984\n",
      "Training batch 17 last loss: 0.09501278400421143\n",
      "\n",
      "Training epoch 5 loss:  0.09501278400421143\n",
      "Epoch 5, Validation Loss: 1.5183325290679932, Validation Accuracy: 82.08955223880598%\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_map))\n",
    "\n",
    "# Set device (GPU/CPU)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer, Loss function\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):  # Adjust number of epochs as needed\n",
    "    print(\"Epoch: \",(epoch + 1))\n",
    "    model.train()\n",
    "    for i,batch in enumerate(train_loader): \n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        pred = outputs.logits\n",
    "        loss = loss_fn(pred, batch['labels'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_batch_loss = loss.item()\n",
    "        train_last_loss = train_batch_loss / 16\n",
    "        print('Training batch {} last loss: {}'.format(i + 1, train_last_loss))\n",
    "    print(f\"\\nTraining epoch {epoch + 1} loss: \",train_last_loss)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}, Validation Loss: {val_loss / len(val_loader)}, Validation Accuracy: {(correct / total) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Infrastructure']\n"
     ]
    }
   ],
   "source": [
    "new_texts = [\n",
    "    \"\"\"\n",
    "    ICT Service Desk Manager EUMETSAT is Europe ’ s meteorological satellite agency - monitoring the weather and climate from space - 24 hours a day , 365 days a year . Working for EUMETSAT , \n",
    "    you can make a world of difference and be a part of something that makes a positive impact on society . You will be at the cutting edge of satellite technology , \n",
    "    with a meaningful role in an organisation focused on space - based observations of the Earth ’ s weather and climate . In the EUMETSAT matrix organisation , \n",
    "    the Information and Communication Technology ( ICT ) Division is responsible for providing applications and support services regarding Information and Communication Technology to the organisation . The ICT Division is a dynamic team of more than 50 technicians and engineers , \n",
    "    which operates , manages , troubleshoots and implements changes to corporate ICT systems , including desktop and mobile IT equipment , SAP , Documentation Management Tool , EUMETSAT web sites and the intranet . In the EUMETSAT matrix organisation , the Information and Communication Technology ( ICT ) Division is responsible for providing applications and support services regarding Informationand Communication Technology to the organisation . \n",
    "    The ICT Division is a dynamic team of more than 50 technicians and engineers , which operates , manages , troubleshoots andimplements changes to corporate ICT systems , \n",
    "    including desktop and mobile IT equipment , SAP , Documentation Management Tool , EUMETSAT web sites and the intranet . As the ICT Service Desk Manager , \n",
    "    you will play a pivotal role in ensuring the smooth operation of our service provision . Your responsibilities will include maintaining service quality and ensuring user satisfaction . \n",
    "    With EUMETSAT embarking on an exciting phase marked by multiple upcoming satellite launches , joining our multi - cultural team presents both challenges and opportunities for personal and professional growth . \n",
    "    What you ’ ll be doing : Under the direct supervision of the ICT Service Delivery Manager and working within the matrix structure of the ICT Division , the Service Desk Manager will be responsible for : Operate the Service Desk , including management of a team of 7 technicians . \n",
    "    Coordinate and implement IT Incident Management and Change Management processes , adhering to existing Service Level Agreements . Ensure timely communication with users and management , \n",
    "    and handle service requests . Provide user support for all IT services and contribute to technical support within the team . Document the team ’ s technical knowledge . \n",
    "    Procure and manage end - user IT equipment ( laptops , phones ) and shared equipment ( corridor printers , meeting room devices ) . Maintain an up - to - date inventory of ICT equipment . \n",
    "    Assist with large deployments of software and devices , including relevant end - user communication . Advise on overall strategies for user support , productivity , roll - out projects , \n",
    "    and training needs . Act as a deputy for the ICT Service Delivery Manager . What we offer : Excellent salary , of up to Euro 8000 NET ( after tax ) based on skills and experience ; \n",
    "    Flexible working time including additional flexi - leave ; Full medical coverage for employee and family ; Attractive pension ; 30 days of annual leave + 14 . 5 days public holidays ; \n",
    "    Training and development support ; Relocation allowance and support ( if applicable ) . \n",
    "    Requirements : Qualifications : Completed secondary education and possess appropriate professional qualifications . \n",
    "    Skills and Experience Requirements : Minimum five years experience in managing IT user support and helpdesk teams . Experience in IT system and application user support and administration . \n",
    "    Extensive experience in supporting and interacting with demanding stakeholders , customers and users of IT Services . Strong customer focus . Strong interpersonal skills , \n",
    "    with proven ability to apply these to interact with management and working within , and across , teams . Flexibility to adapt to changing organisational priorities and user needs . \n",
    "    Knowledge of ISO 9000 and ITIL , as well as knowledge and hands - on experience with the following are desirable : Microsoft 365 , Atlassian Jira & Confluence . \n",
    "    Languages : Candidates need to be able to work effectively in English More about us : EUMETSAT ’ s role is to establish and operate meteorological satellites to monitor the weather and climate from space - 24 hours a day , 365 days a year . \n",
    "    This information is supplied to the National Meteorological Services of the organisation ' s Member and Cooperating States in Europe , as well as other users worldwide . \n",
    "    EUMETSAT also operates several Copernicus missions on behalf of the European Union and provide data services to the Copernicus marine and atmospheric services and their users . \n",
    "    As an intergovernmental European Organisation , EUMETSAT can recruit nationals only from the 30 Member States ( Austria , Belgium , Bulgaria , Croatia , Czech Republic , Denmark , Estonia , Finland , France , Germany , Greece , Hungary , Iceland , Ireland , Italy , Latvia , Lithuania , Luxembourg , The Netherlands , Norway , Poland , Portugal , Romania , Slovakia , Slovenia , Spain , Sweden , Switzerland , Turkey and the United Kingdom ) . \n",
    "    Show more Show less Information Technology Defense and Space Manufacturing\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "inputs = tokenizer(new_texts, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "model.eval()\n",
    "# Realizar predicciones\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Obtener las predicciones de clase\n",
    "predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "# Convertir las predicciones de índices a etiquetas (si se desea)\n",
    "predicted_labels = [list(label_map.keys())[list(label_map.values()).index(pred)] for pred in predictions]\n",
    "\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['segment_model.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar el modelo\n",
    "joblib.dump(model, 'segment_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'Test_Results_Translated'\n",
    "excel_file = '../' + fileName + '.xlsx'\n",
    "\n",
    "df = pd.read_excel(excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "jobTypes = []\n",
    "\n",
    "for text in df['Descriptions'].to_list():\n",
    "    inputs = tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    model.eval()\n",
    "    # Realizar predicciones\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Obtener las predicciones de clase\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    # Convertir las predicciones de índices a etiquetas (si se desea)\n",
    "    predicted_labels = [list(label_map.keys())[list(label_map.values()).index(pred)] for pred in predictions]\n",
    "\n",
    "    finalResult = ''\n",
    "    if not predicted_labels:\n",
    "        finalResult = \"Undefined\"\n",
    "    else:\n",
    "        finalResult = predicted_labels[0]\n",
    "    jobTypes.append(finalResult)\n",
    "    \n",
    "df['MarketSegment'] = jobTypes\n",
    "df.to_excel('../' + fileName + '_Segment.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 51.11%\n",
      "\n",
      " ----------------------------- \n",
      "\n",
      "Document Annotated\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "true_categories = df['Segment'].tolist()\n",
    "predicted_categories = df['MarketSegment'].tolist()\n",
    "\n",
    "# Count correct predictions\n",
    "correct_predictions = sum(1 for true, pred in zip(true_categories, predicted_categories) if true == pred)\n",
    "\n",
    "# Calculate percentage accuracy\n",
    "accuracy = (correct_predictions / len(jobTypes)) * 100\n",
    "\n",
    "# Print the result\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\n ----------------------------- \\n\")\n",
    "print(\"Document Annotated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
