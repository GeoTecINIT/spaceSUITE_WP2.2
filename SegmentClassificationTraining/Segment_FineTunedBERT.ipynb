{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning BERT for Segment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "excel_file = './Segment_Training_Data.xlsx'\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "descriptions = df['Descriptions'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Tokenization of Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tokenized_texts = tokenizer(descriptions, truncation=True, padding=True)\n",
    "\n",
    "combined_texts = [{'input_ids': input_ids, 'attention_mask': attention_mask} \n",
    "                  for input_ids, attention_mask in zip(tokenized_texts['input_ids'], tokenized_texts['attention_mask'])]\n",
    "\n",
    "labels = list(df['Segment'])\n",
    "\n",
    "label_map = {'Space': 0,\n",
    " 'Maritime and Inland Waterways': 1,\n",
    " 'Consumer Solutions, Tourism and Health': 2,\n",
    " 'Infrastructure': 3,\n",
    " 'Road and Automotive': 4,\n",
    " 'Fisheries and Aquaculture': 5,\n",
    " 'Emergency Management and Humanitarian Aid': 6,\n",
    " 'Climate, Environment, and Biodiversity ': 7,\n",
    " 'Insurance and Finance': 8,\n",
    " 'Rail': 9,\n",
    " 'Aviation and Drones': 10,\n",
    " 'Urban Development and Cultural Heritage': 11,\n",
    " 'Rail ': 12,\n",
    " 'Forestry': 13,\n",
    " 'Energy and Raw Materials': 14,\n",
    " 'Agriculture': 15}\n",
    "labels = [label_map[label] for label in labels]\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(combined_texts, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'input_ids': torch.tensor(self.encodings[idx]['input_ids'], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(self.encodings[idx]['attention_mask'], dtype=torch.long),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = CustomDataset(train_texts, train_labels)\n",
    "val_dataset = CustomDataset(val_texts, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setup and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Training batch 1 last loss: 0.16955985128879547\n",
      "Training batch 2 last loss: 0.18108126521110535\n",
      "Training batch 3 last loss: 0.17587529122829437\n",
      "Training batch 4 last loss: 0.17251430451869965\n",
      "Training batch 5 last loss: 0.1768403798341751\n",
      "Training batch 6 last loss: 0.1816202998161316\n",
      "Training batch 7 last loss: 0.1765003353357315\n",
      "Training batch 8 last loss: 0.17923958599567413\n",
      "Training batch 9 last loss: 0.18498387932777405\n",
      "Training batch 10 last loss: 0.17030440270900726\n",
      "Training batch 11 last loss: 0.17372581362724304\n",
      "Training batch 12 last loss: 0.16715452075004578\n",
      "Training batch 13 last loss: 0.17768484354019165\n",
      "Training batch 14 last loss: 0.16905170679092407\n",
      "Training batch 15 last loss: 0.16286662220954895\n",
      "Training batch 16 last loss: 0.16876320540905\n",
      "Training batch 17 last loss: 0.15728195011615753\n",
      "\n",
      "Training epoch 1 loss:  0.15728195011615753\n",
      "Epoch 1, Validation Loss: 2.6322689056396484, Validation Accuracy: 16.417910447761194%\n",
      "Epoch:  2\n",
      "Training batch 1 last loss: 0.1655016839504242\n",
      "Training batch 2 last loss: 0.17089658975601196\n",
      "Training batch 3 last loss: 0.16214197874069214\n",
      "Training batch 4 last loss: 0.15550623834133148\n",
      "Training batch 5 last loss: 0.15807665884494781\n",
      "Training batch 6 last loss: 0.16076557338237762\n",
      "Training batch 7 last loss: 0.16417984664440155\n",
      "Training batch 8 last loss: 0.15781742334365845\n",
      "Training batch 9 last loss: 0.1643829494714737\n",
      "Training batch 10 last loss: 0.16138818860054016\n",
      "Training batch 11 last loss: 0.16505864262580872\n",
      "Training batch 12 last loss: 0.14868327975273132\n",
      "Training batch 13 last loss: 0.16323541104793549\n",
      "Training batch 14 last loss: 0.1605762243270874\n",
      "Training batch 15 last loss: 0.16143369674682617\n",
      "Training batch 16 last loss: 0.15859673917293549\n",
      "Training batch 17 last loss: 0.16393537819385529\n",
      "\n",
      "Training epoch 2 loss:  0.16393537819385529\n",
      "Epoch 2, Validation Loss: 2.4132933616638184, Validation Accuracy: 26.865671641791046%\n",
      "Epoch:  3\n",
      "Training batch 1 last loss: 0.1525176465511322\n",
      "Training batch 2 last loss: 0.14206022024154663\n",
      "Training batch 3 last loss: 0.14447210729122162\n",
      "Training batch 4 last loss: 0.14352484047412872\n",
      "Training batch 5 last loss: 0.14931514859199524\n",
      "Training batch 6 last loss: 0.149892657995224\n",
      "Training batch 7 last loss: 0.14473654329776764\n",
      "Training batch 8 last loss: 0.14075186848640442\n",
      "Training batch 9 last loss: 0.148402139544487\n",
      "Training batch 10 last loss: 0.13844361901283264\n",
      "Training batch 11 last loss: 0.13820363581180573\n",
      "Training batch 12 last loss: 0.1446179449558258\n",
      "Training batch 13 last loss: 0.13549965620040894\n",
      "Training batch 14 last loss: 0.1392887830734253\n",
      "Training batch 15 last loss: 0.1495562493801117\n",
      "Training batch 16 last loss: 0.14095625281333923\n",
      "Training batch 17 last loss: 0.14083117246627808\n",
      "\n",
      "Training epoch 3 loss:  0.14083117246627808\n",
      "Epoch 3, Validation Loss: 2.1468018770217894, Validation Accuracy: 41.7910447761194%\n",
      "Epoch:  4\n",
      "Training batch 1 last loss: 0.13204896450042725\n",
      "Training batch 2 last loss: 0.13045619428157806\n",
      "Training batch 3 last loss: 0.13127240538597107\n",
      "Training batch 4 last loss: 0.12616373598575592\n",
      "Training batch 5 last loss: 0.13338246941566467\n",
      "Training batch 6 last loss: 0.12019214034080505\n",
      "Training batch 7 last loss: 0.13444571197032928\n",
      "Training batch 8 last loss: 0.12363111972808838\n",
      "Training batch 9 last loss: 0.12270625680685043\n",
      "Training batch 10 last loss: 0.13788114488124847\n",
      "Training batch 11 last loss: 0.11433427780866623\n",
      "Training batch 12 last loss: 0.122410349547863\n",
      "Training batch 13 last loss: 0.1118566244840622\n",
      "Training batch 14 last loss: 0.11120747029781342\n",
      "Training batch 15 last loss: 0.11863207817077637\n",
      "Training batch 16 last loss: 0.1240740567445755\n",
      "Training batch 17 last loss: 0.12078504264354706\n",
      "\n",
      "Training epoch 4 loss:  0.12078504264354706\n",
      "Epoch 4, Validation Loss: 1.7811297178268433, Validation Accuracy: 85.07462686567165%\n",
      "Epoch:  5\n",
      "Training batch 1 last loss: 0.10075528919696808\n",
      "Training batch 2 last loss: 0.10773590952157974\n",
      "Training batch 3 last loss: 0.12065073102712631\n",
      "Training batch 4 last loss: 0.1016145721077919\n",
      "Training batch 5 last loss: 0.10762990266084671\n",
      "Training batch 6 last loss: 0.09958972781896591\n",
      "Training batch 7 last loss: 0.10481590777635574\n",
      "Training batch 8 last loss: 0.09547700732946396\n",
      "Training batch 9 last loss: 0.1071765124797821\n",
      "Training batch 10 last loss: 0.0996178686618805\n",
      "Training batch 11 last loss: 0.1154526099562645\n",
      "Training batch 12 last loss: 0.0937691256403923\n",
      "Training batch 13 last loss: 0.09715132415294647\n",
      "Training batch 14 last loss: 0.10078154504299164\n",
      "Training batch 15 last loss: 0.09449127316474915\n",
      "Training batch 16 last loss: 0.09308025240898132\n",
      "Training batch 17 last loss: 0.09505225718021393\n",
      "\n",
      "Training epoch 5 loss:  0.09505225718021393\n",
      "Epoch 5, Validation Loss: 1.4020050048828125, Validation Accuracy: 89.55223880597015%\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_map))\n",
    "\n",
    "# Set device (GPU/CPU)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer, Loss function\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):  # Adjust number of epochs as needed\n",
    "    print(\"Epoch: \",(epoch + 1))\n",
    "    model.train()\n",
    "    for i,batch in enumerate(train_loader): \n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        pred = outputs.logits\n",
    "        loss = loss_fn(pred, batch['labels'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_batch_loss = loss.item()\n",
    "        train_last_loss = train_batch_loss / 16\n",
    "        print('Training batch {} last loss: {}'.format(i + 1, train_last_loss))\n",
    "    print(f\"\\nTraining epoch {epoch + 1} loss: \",train_last_loss)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}, Validation Loss: {val_loss / len(val_loader)}, Validation Accuracy: {(correct / total) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Infrastructure']\n"
     ]
    }
   ],
   "source": [
    "new_texts = [\n",
    "    \"\"\"\n",
    "    ICT Service Desk Manager EUMETSAT is Europe ’ s meteorological satellite agency - monitoring the weather and climate from space - 24 hours a day , 365 days a year . Working for EUMETSAT , \n",
    "    you can make a world of difference and be a part of something that makes a positive impact on society . You will be at the cutting edge of satellite technology , \n",
    "    with a meaningful role in an organisation focused on space - based observations of the Earth ’ s weather and climate . In the EUMETSAT matrix organisation , \n",
    "    the Information and Communication Technology ( ICT ) Division is responsible for providing applications and support services regarding Information and Communication Technology to the organisation . The ICT Division is a dynamic team of more than 50 technicians and engineers , \n",
    "    which operates , manages , troubleshoots and implements changes to corporate ICT systems , including desktop and mobile IT equipment , SAP , Documentation Management Tool , EUMETSAT web sites and the intranet . In the EUMETSAT matrix organisation , the Information and Communication Technology ( ICT ) Division is responsible for providing applications and support services regarding Informationand Communication Technology to the organisation . \n",
    "    The ICT Division is a dynamic team of more than 50 technicians and engineers , which operates , manages , troubleshoots andimplements changes to corporate ICT systems , \n",
    "    including desktop and mobile IT equipment , SAP , Documentation Management Tool , EUMETSAT web sites and the intranet . As the ICT Service Desk Manager , \n",
    "    you will play a pivotal role in ensuring the smooth operation of our service provision . Your responsibilities will include maintaining service quality and ensuring user satisfaction . \n",
    "    With EUMETSAT embarking on an exciting phase marked by multiple upcoming satellite launches , joining our multi - cultural team presents both challenges and opportunities for personal and professional growth . \n",
    "    What you ’ ll be doing : Under the direct supervision of the ICT Service Delivery Manager and working within the matrix structure of the ICT Division , the Service Desk Manager will be responsible for : Operate the Service Desk , including management of a team of 7 technicians . \n",
    "    Coordinate and implement IT Incident Management and Change Management processes , adhering to existing Service Level Agreements . Ensure timely communication with users and management , \n",
    "    and handle service requests . Provide user support for all IT services and contribute to technical support within the team . Document the team ’ s technical knowledge . \n",
    "    Procure and manage end - user IT equipment ( laptops , phones ) and shared equipment ( corridor printers , meeting room devices ) . Maintain an up - to - date inventory of ICT equipment . \n",
    "    Assist with large deployments of software and devices , including relevant end - user communication . Advise on overall strategies for user support , productivity , roll - out projects , \n",
    "    and training needs . Act as a deputy for the ICT Service Delivery Manager . What we offer : Excellent salary , of up to Euro 8000 NET ( after tax ) based on skills and experience ; \n",
    "    Flexible working time including additional flexi - leave ; Full medical coverage for employee and family ; Attractive pension ; 30 days of annual leave + 14 . 5 days public holidays ; \n",
    "    Training and development support ; Relocation allowance and support ( if applicable ) . \n",
    "    Requirements : Qualifications : Completed secondary education and possess appropriate professional qualifications . \n",
    "    Skills and Experience Requirements : Minimum five years experience in managing IT user support and helpdesk teams . Experience in IT system and application user support and administration . \n",
    "    Extensive experience in supporting and interacting with demanding stakeholders , customers and users of IT Services . Strong customer focus . Strong interpersonal skills , \n",
    "    with proven ability to apply these to interact with management and working within , and across , teams . Flexibility to adapt to changing organisational priorities and user needs . \n",
    "    Knowledge of ISO 9000 and ITIL , as well as knowledge and hands - on experience with the following are desirable : Microsoft 365 , Atlassian Jira & Confluence . \n",
    "    Languages : Candidates need to be able to work effectively in English More about us : EUMETSAT ’ s role is to establish and operate meteorological satellites to monitor the weather and climate from space - 24 hours a day , 365 days a year . \n",
    "    This information is supplied to the National Meteorological Services of the organisation ' s Member and Cooperating States in Europe , as well as other users worldwide . \n",
    "    EUMETSAT also operates several Copernicus missions on behalf of the European Union and provide data services to the Copernicus marine and atmospheric services and their users . \n",
    "    As an intergovernmental European Organisation , EUMETSAT can recruit nationals only from the 30 Member States ( Austria , Belgium , Bulgaria , Croatia , Czech Republic , Denmark , Estonia , Finland , France , Germany , Greece , Hungary , Iceland , Ireland , Italy , Latvia , Lithuania , Luxembourg , The Netherlands , Norway , Poland , Portugal , Romania , Slovakia , Slovenia , Spain , Sweden , Switzerland , Turkey and the United Kingdom ) . \n",
    "    Show more Show less Information Technology Defense and Space Manufacturing\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "inputs = tokenizer(new_texts, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "model.eval()\n",
    "# Realizar predicciones\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Obtener las predicciones de clase\n",
    "predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "# Convertir las predicciones de índices a etiquetas (si se desea)\n",
    "predicted_labels = [list(label_map.keys())[list(label_map.values()).index(pred)] for pred in predictions]\n",
    "\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['segment_model.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar el modelo\n",
    "joblib.dump(model, 'segment_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'Test_Results_Translated'\n",
    "excel_file = '../' + fileName + '.xlsx'\n",
    "\n",
    "df = pd.read_excel(excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "jobTypes = []\n",
    "\n",
    "for text in df['Descriptions'].to_list():\n",
    "    inputs = tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    model.eval()\n",
    "    # Realizar predicciones\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Obtener las predicciones de clase\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    # Convertir las predicciones de índices a etiquetas (si se desea)\n",
    "    predicted_labels = [list(label_map.keys())[list(label_map.values()).index(pred)] for pred in predictions]\n",
    "\n",
    "    finalResult = ''\n",
    "    if not predicted_labels:\n",
    "        finalResult = \"Undefined\"\n",
    "    else:\n",
    "        finalResult = predicted_labels[0]\n",
    "    jobTypes.append(finalResult)\n",
    "    \n",
    "df['MarketSegment'] = jobTypes\n",
    "df.to_excel('../' + fileName + '_Segment.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 44.44%\n",
      "\n",
      " ----------------------------- \n",
      "\n",
      "Document Annotated\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "true_categories = df['Segment'].tolist()\n",
    "predicted_categories = df['MarketSegment'].tolist()\n",
    "\n",
    "# Count correct predictions\n",
    "correct_predictions = sum(1 for true, pred in zip(true_categories, predicted_categories) if true == pred)\n",
    "\n",
    "# Calculate percentage accuracy\n",
    "accuracy = (correct_predictions / len(jobTypes)) * 100\n",
    "\n",
    "# Print the result\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\n ----------------------------- \\n\")\n",
    "print(\"Document Annotated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
