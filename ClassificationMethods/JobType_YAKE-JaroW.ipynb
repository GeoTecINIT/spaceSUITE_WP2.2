{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Type YAKE Jaro-Winkler Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "excel_file = './Euraxess_GNSS_Keywords.xlsx'\n",
    "df = pd.read_excel(excel_file)\n",
    "\n",
    "_, sampled_df = train_test_split(df, test_size=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df['Concatenated'] = sampled_df[['Title', 'OfferDescription', 'Requirements', 'AdditionalInformation']].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n",
    "\n",
    "descriptions = sampled_df['Title'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions_token = []\n",
    "\n",
    "for description in descriptions:\n",
    "    tokens = word_tokenize(description)\n",
    "    descriptions_token.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Hyphens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hyphens(text):\n",
    "    return [item.strip('-') for item in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_hyphens = []\n",
    "\n",
    "for description in descriptions_token:\n",
    "    tokens = remove_hyphens(description)\n",
    "    rem_hyphens.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowcase all the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_text(text):\n",
    "    return [item.lower() for item in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowcase_descriptions = []\n",
    "\n",
    "for description in rem_hyphens:\n",
    "    tokens = lowercase_text(description)\n",
    "    lowcase_descriptions.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_case(text):\n",
    "    return [item.strip('[]') for item in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_casing = []\n",
    "\n",
    "for description in lowcase_descriptions:\n",
    "    tokens = remove_case(description)\n",
    "    rem_casing.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    return [word for word in text if word.casefold() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_stopwords = []\n",
    "\n",
    "for description in rem_casing:\n",
    "    tokens = remove_stopwords(description)\n",
    "    rem_stopwords.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unicode symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "unicode_regex = re.compile(r'[^\\x00-\\x7F]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unicode(text):\n",
    "    return [word for word in text if not unicode_regex.search(word)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_unicode = []\n",
    "\n",
    "for description in rem_stopwords:\n",
    "    tokens = remove_unicode(description)\n",
    "    rem_unicode.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove numbers and digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_regex = re.compile(r'\\d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_number(text):\n",
    "    return [word for word in text if not number_regex.search(word)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_number = []\n",
    "\n",
    "for description in rem_unicode:\n",
    "    tokens = remove_number(description)\n",
    "    rem_number.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Special Words Mixed with String, Numbers, Punctuation, and Other Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_regex = re.compile(r'^(?=.*\\d)(?=.*[A-Za-z])|(?=.*[A-Za-z])(?=.*[\\W_])|(?=.*\\d)(?=.*[\\W_])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special(text):\n",
    "    return [word for word in text if not special_regex.search(word)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_special = []\n",
    "\n",
    "for description in rem_number:\n",
    "    tokens = remove_special(description)\n",
    "    rem_special.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_regex = re.compile(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    return [word for word in text if not url_regex.search(word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_url = []\n",
    "\n",
    "for description in rem_special:\n",
    "    tokens = remove_url(description)\n",
    "    rem_url.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punct(text):\n",
    "    return [word for word in text if word not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_punct = []\n",
    "\n",
    "for description in rem_url:\n",
    "    tokens = remove_punct(description)\n",
    "    rem_punct.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(arr):\n",
    "    return list(set(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_dupl = []\n",
    "\n",
    "for description in rem_punct:\n",
    "    tokens = remove_duplicates(description)\n",
    "    rem_dupl.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove single characters and non-english words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import words\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_words = set(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_eng(text):\n",
    "    return [word for word in text if word in english_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_single_char_words(arr):\n",
    "    return list(filter(lambda word: len(word) > 1, arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_noEnglish = []\n",
    "\n",
    "for description in rem_dupl:\n",
    "    tokens = remove_non_eng(description)\n",
    "    tokens = remove_single_char_words(tokens)\n",
    "    rem_noEnglish.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove spelling mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "def remove_misspelled_words(arr):\n",
    "    spell = SpellChecker()\n",
    "    return [word for word in arr if word in spell]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_misspelled = []\n",
    "\n",
    "for description in rem_noEnglish:\n",
    "    tokens = remove_misspelled_words(description)\n",
    "    rem_misspelled.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "\n",
    "# Initialize wordnet lemmatizer\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lematize(arr):\n",
    "    return [wnl.lemmatize(word) for word in arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_texts = []\n",
    "\n",
    "for description in rem_misspelled:\n",
    "    tokens = lematize(description)\n",
    "    cleaned_texts.append(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YAKE (Yet Another Keyword Extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glue_texts(array):\n",
    "    return [' '.join(tokens) for tokens in array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_texts = glue_texts(cleaned_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YAKE\n",
    "language = \"en\"  # Language of the text\n",
    "max_ngram_size = 3  # Maximum length of the keyword phrases\n",
    "deduplication_threshold = 0.9  # Deduplication threshold\n",
    "num_keywords = 10  # Number of keywords to extract\n",
    "\n",
    "kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, top=num_keywords, features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_per_text = []\n",
    "for text in final_texts:\n",
    "    keywords = kw_extractor.extract_keywords(text)\n",
    "    keywords_per_text.append([item[0] for item in keywords])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaro-Winkler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_map = {\n",
    "    \"Management\": [\n",
    "        \"General Manager\", \"CEO\", \"Executive Director\", \"Operations Manager\", \"Project Leader\",\n",
    "        \"Program Director\", \"Department Head\", \"Executive Officer\", \"Division Head\", \"Branch Director\",\n",
    "        \"Regional Director\", \"Country Director\", \"Site Director\", \"Organizational Development\",\n",
    "        \"Business Strategy\", \"Leadership Development\", \"Management Consulting\", \"Team Leadership\",\n",
    "        \"Performance Management\", \"Employee Development\", \"Talent Management\", \"Succession Planning\",\n",
    "        \"Conflict Resolution\", \"Staff Management\", \"Workforce Planning\", \"Goal Setting\", \"Performance Appraisal\",\n",
    "        \"HR Management\", \"Financial Management\", \"Marketing Management\", \"Sales Management\",\n",
    "        \"Product Management\", \"IT Management\", \"Quality Management\", \"Supply Chain Management\",\n",
    "        \"Risk Management\", \"Compliance Management\", \"Customer Service Management\", \"Facilities Management\",\n",
    "        \"Administrative Management\", \"Corporate Governance\", \"Business Operations\", \"Stakeholder Management\",\n",
    "        \"Process Improvement\", \"Business Continuity\", \"KPI Management\", \"Resource Allocation\", \"Crisis Management\",\n",
    "        \"Innovation Management\", \"Knowledge Management\", \"Strategic Initiatives\", \"Organizational Behavior\",\n",
    "        \"Change Leadership\", \"Strategic Execution\", \"Leadership Communication\", \"Decision Making\",\n",
    "        \"Resource Optimization\"\n",
    "    ],\n",
    "    \"Sales and Marketing\": [\n",
    "        \"Sales Representative\", \"Sales Manager\", \"Sales Director\", \"Account Executive\",\n",
    "        \"Business Development Representative\", \"Sales Specialist\", \"Marketing Manager\", \"Product Manager\",\n",
    "        \"Marketing Director\", \"Marketing Specialist\", \"Digital Marketing Manager\", \"Content Marketing Manager\",\n",
    "        \"SEO Specialist\", \"Business Development\", \"Market Research\", \"Advertising\", \"Sales Strategies\",\n",
    "        \"Customer Relationship Management\", \"Digital Marketing\", \"Social Media Marketing\", \"Public Relations\",\n",
    "        \"Content Marketing\", \"Email Marketing\", \"Lead Generation\", \"Campaign Management\", \"Market Segmentation\",\n",
    "        \"Sales Forecasting\", \"Customer Engagement\", \"Sales Operations\", \"Promotional Strategies\", \"Sales Enablement\",\n",
    "        \"Marketing Communications\", \"Consumer Behavior\", \"Sales Analytics\", \"Market Analysis\", \"Brand Management\",\n",
    "        \"Customer Insights\", \"Campaign Strategy\", \"Content Strategy\", \"Digital Advertising\", \"Sales Optimization\",\n",
    "        \"Customer Experience Management\", \"Influencer Marketing\", \"Growth Hacking\", \"Performance Marketing\"\n",
    "    ],\n",
    "    \"Engineering and Science\": [\n",
    "        \"Software Engineer\", \"Mechanical Engineer\", \"Electrical Engineer\", \"Civil Engineer\", \"Structural Engineer\",\n",
    "        \"Chemical Engineer\", \"Environmental Engineer\", \"Industrial Engineer\", \"Systems Engineer\", \"Hardware Engineer\",\n",
    "        \"IT Support Specialist\", \"Data Analyst\", \"Systems Analyst\", \"Network Engineer\", \"Database Administrator\",\n",
    "        \"Cybersecurity Specialist\", \"Cloud Computing Specialist\", \"DevOps Engineer\", \"AI Developer\", \"Software Developer\",\n",
    "        \"IT Project Manager\", \"Software Development\", \"Network Security\", \"Cloud Services\", \"Data Management\",\n",
    "        \"Systems Integration\", \"Quality Assurance\", \"Data Engineering\", \"IT Management\", \"Software Architecture\",\n",
    "        \"Digital Transformation\", \"Application Development\", \"Hardware Design\", \"Systems Engineering\",\n",
    "        \"Network Architecture\", \"Cybersecurity Protocols\", \"Data Analytics\", \"Cloud Infrastructure\",\n",
    "        \"Emerging Technologies\", \"Geospatial Analysis\", \"Spatial Data Management\", \"Remote Sensing\",\n",
    "        \"Artificial Intelligence\", \"Machine Learning\", \"Robotics\", \"Big Data Analytics\", \"IoT\", \"Computational Science\",\n",
    "        \"Mathematician\", \"Statistician\", \"Data Scientist\", \"Quantitative Analyst\", \"Actuary\",\n",
    "        \"Mathematical Modeler\", \"Operations Research Analyst\", \"Physicist\", \"Chemist\", \"Astronomer\",\n",
    "        \"Geophysicist\", \"Environmental Scientist\", \"Biochemist\", \"Research Scientist\", \"Laboratory Technician\",\n",
    "        \"Climate Scientist\", \"Mathematical Analysis\", \"Data Modeling\", \"Statistical Analysis\", \"Experimental Research\",\n",
    "        \"Environmental Analysis\", \"Scientific Research\", \"Applied Mathematics\", \"Physical Chemistry\",\n",
    "        \"Organic Chemistry\", \"Inorganic Chemistry\", \"Astrophysics\", \"Quantum Mechanics\",\n",
    "        \"Photonics\", \"Laser Technology\", \"Quantum Computing\", \"Scientific Data Analysis\", \"Experimental Physics\",\n",
    "        \"Statistical Mechanics\", \"Spatial Statistics\", \"Geostatistics\", \"Environmental Modeling\",\n",
    "        \"Neuroscience\", \"Computational Biology\", \"Bioinformatics\", \"Complex Systems\", \"Neurorehabilitation\",\n",
    "        \"Trauma Care\", \"Psychiatric Medicine\", \"Geriatric Medicine\", \"Telemedicine\"\n",
    "    ],\n",
    "    \"Finance\": [\n",
    "        \"Accountant\", \"Financial Analyst\", \"Controller\", \"Auditor\", \"Budget Analyst\", \"Investment Analyst\",\n",
    "        \"Treasury Analyst\", \"Risk Manager\", \"Tax Advisor\", \"Credit Analyst\", \"Cash Flow Manager\",\n",
    "        \"Financial Records\", \"Financial Analysis\", \"Compliance\", \"Office Management\", \"Budget Management\",\n",
    "        \"Payroll Management\", \"Accounts Payable\", \"Accounts Receivable\", \"Financial Planning\", \"Corporate Finance\",\n",
    "        \"Cost Accounting\", \"Management Accounting\", \"Financial Reporting\", \"Internal Audit\", \"Business Valuation\",\n",
    "        \"Asset Management\", \"Credit Management\", \"Financial Risk Management\", \"Regulatory Compliance\", \"Treasury Management\",\n",
    "        \"Financial Modeling\", \"Risk Assessment\", \"Budget Planning\", \"Audit Procedures\", \"Financial Strategy\",\n",
    "        \"Administrative Operations\", \"Expense Management\", \"Financial Technology\", \"Fintech Innovations\",\n",
    "        \"Equity Research Analyst\", \"Portfolio Manager\", \"Investment Banker\", \"Financial Consultant\",\n",
    "        \"Hedge Fund Manager\", \"Private Equity Analyst\", \"Venture Capital Analyst\", \"Corporate Treasurer\",\n",
    "        \"Financial Advisor\", \"Commercial Banker\", \"Loan Officer\", \"Trade Analyst\", \"Merger and Acquisition Analyst\",\n",
    "        \"Forensic Accountant\", \"Tax Planner\", \"Estate Planner\", \"Credit Risk Analyst\", \"Quantitative Finance Analyst\",\n",
    "        \"Personal Financial Advisor\", \"Insurance Underwriter\", \"Pension Fund Manager\", \"Real Estate Finance Specialist\"\n",
    "    ],\n",
    "    \"Administration\": [\n",
    "        \"Administrative Assistant\", \"Office Manager\", \"Executive Assistant\", \"Office Administrator\",\n",
    "        \"Receptionist\", \"Clerical Assistant\", \"Data Entry Clerk\", \"Office Coordinator\",\n",
    "        \"Administrative Coordinator\", \"Secretary\", \"Personal Assistant\", \"Administrative Manager\",\n",
    "        \"Front Desk Coordinator\", \"Customer Service Administrator\", \"Records Manager\", \"Office Support Specialist\",\n",
    "        \"Mailroom Clerk\", \"File Clerk\", \"Virtual Assistant\", \"Scheduling Coordinator\", \"Office Operations Manager\",\n",
    "        \"Office Support Supervisor\", \"Executive Secretary\", \"Administrative Support Specialist\", \"Administrative Officer\",\n",
    "        \"Office Supervisor\", \"Administrative Director\", \"Facilities Coordinator\", \"Document Controller\",\n",
    "        \"Administrative Receptionist\", \"Office Assistant\", \"Operations Administrator\"\n",
    "    ],\n",
    "    \"Technical Works\": [\n",
    "        \"Electrician\", \"Plumber\", \"Carpenter\", \"Welder\", \"Machinist\", \"Machine Operator\", \"HVAC Technician\",\n",
    "        \"Automotive Technician\", \"Diesel Mechanic\", \"Industrial Mechanic\", \"Maintenance Technician\",\n",
    "        \"Construction Worker\", \"Heavy Equipment Operator\", \"Line Installer\", \"Cable Technician\", \"Elevator Installer\",\n",
    "        \"Boilermaker\", \"Roofer\", \"Painter\", \"Bricklayer\", \"Forklift Operator\", \"CNC Operator\", \"Tool and Die Maker\",\n",
    "        \"Sheet Metal Worker\", \"Pipefitter\", \"Insulation Worker\", \"Crane Operator\", \"Paving Equipment Operator\",\n",
    "        \"Rig Operator\", \"Power Plant Operator\", \"Wind Turbine Technician\", \"Solar Panel Installer\", \"Glazier\",\n",
    "        \"Lineman\", \"Telecommunications Technician\", \"Security System Installer\", \"Locksmith\",\n",
    "        \"Septic Tank Servicer\", \"Gas Appliance Technician\", \"Aircraft Mechanic\", \"Marine Mechanic\",\n",
    "        \"Railroad Technician\", \"Signal and Track Switch Repairer\", \"Nuclear Technician\", \"Petroleum Technician\",\n",
    "        \"Textile Worker\", \"Printing Press Operator\", \"Quality Control Inspector\", \"Warehouse Associate\",\n",
    "        \"Logistics Coordinator\", \"Material Handler\", \"Production Worker\", \"Assembler\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaro import jaro_winkler_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(extracted_keywords, category_map):\n",
    "    similarity_scores = {}\n",
    "    \n",
    "    def compute_max_similarity(keywords, category_keywords):\n",
    "        max_similarity = 0\n",
    "        for kw in keywords:\n",
    "            for cat_kw in category_keywords:\n",
    "                similarity = jaro_winkler_metric(kw, cat_kw)\n",
    "                if similarity > max_similarity:\n",
    "                    max_similarity = similarity\n",
    "        return max_similarity\n",
    "\n",
    "    for category, keywords in category_map.items():\n",
    "        similarity = compute_max_similarity(extracted_keywords, keywords)\n",
    "        similarity_scores[category] = similarity\n",
    "    \n",
    "    best_category = max(similarity_scores, key=similarity_scores.get)\n",
    "    return best_category, similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fellowship', 'hosting', 'engineering', 'civil', 'candidate'] Engineering and IT 0.8596491228070176\n",
      "['doctoral', 'researcher', 'psychology'] Mathematics and Physical Sciences 0.7666666666666666\n",
      "['magnetic', 'quantum', 'thermodynamic', 'solid', 'physic'] Mathematics and Physical Sciences 0.8333333333333334\n",
      "['professor', 'chemical', 'assistant', 'engineering', 'school'] Engineering and IT 0.8596491228070176\n",
      "['faculty', 'chemistry', 'institute', 'engineering', 'green'] Engineering and IT 0.8596491228070176\n",
      "['spatial', 'postdoctoral', 'data', 'analysis', 'fellow'] Engineering and IT 0.7894736842105262\n",
      "['postdoctoral', 'fellowship', 'food', 'engineering'] Engineering and IT 0.8596491228070176\n",
      "['chancellor', 'decree', 'profile', 'complete', 'refer'] Mathematics and Physical Sciences 0.7805555555555556\n",
      "['gastroenterology', 'doctoral', 'scholarship', 'medicine', 'domain'] Mathematics and Physical Sciences 0.7638888888888888\n",
      "['equipment', 'service', 'innovation'] Engineering and IT 0.7619047619047619\n",
      "['engineer', 'learning', 'data'] Engineering and IT 0.8070175438596491\n",
      "['postdoctoral', 'position', 'precision', 'medicine', 'learning'] Mathematics and Physical Sciences 0.7638888888888888\n",
      "['embryology', 'histology', 'division', 'competition', 'professor'] Management 0.8044871794871794\n",
      "['geophysics', 'lecturer', 'department'] Mathematics and Physical Sciences 0.8833333333333333\n",
      "['protein', 'structural', 'position'] Engineering and IT 0.7912280701754386\n",
      "['manager', 'community'] Finance and Administration 0.7857142857142857\n",
      "['teaching', 'professor', 'competition', 'assistant', 'management'] Management 0.8641025641025641\n",
      "['electronics', 'ai', 'technology'] Mathematics and Physical Sciences 0.8208333333333333\n",
      "['computational', 'study'] Engineering and IT 0.8315018315018315\n",
      "['environmental', 'chemistry', 'engineering', 'academic', 'protection'] Engineering and IT 0.8596491228070176\n",
      "['financial', 'economics', 'management', 'staff', 'assistant'] Management 0.8641025641025641\n",
      "['spatially', 'focus', 'interactive', 'science', 'reason'] Engineering and IT 0.8245614035087719\n",
      "['chemistry'] Mathematics and Physical Sciences 0.8412698412698413\n",
      "['marketing', 'drinking', 'candidate', 'young', 'effect'] Sales and Marketing 0.7925925925925926\n",
      "['nonlinear', 'assimilation', 'subsurface', 'adaptive', 'position'] Sales and Marketing 0.7516835016835017\n",
      "['employment', 'university', 'contract', 'pursuant', 'subordinate'] Finance and Administration 0.763095238095238\n",
      "['veterinary', 'infectious', 'animal', 'therapeutic', 'department'] Management 0.8333333333333334\n",
      "['female', 'position', 'body', 'reading', 'low'] Finance and Administration 0.7563025210084033\n",
      "['position', 'engineering', 'learning', 'explainable', 'machine'] Engineering and IT 0.8596491228070176\n",
      "['fermentation', 'aroma', 'synthesis', 'position', 'control'] Finance and Administration 0.8190476190476191\n",
      "['university', 'didactics', 'organization', 'department', 'joint'] Management 0.8333333333333334\n",
      "['gene', 'causal', 'spatial', 'network', 'dynamic'] Engineering and IT 0.7894736842105262\n",
      "['lecturer', 'psychology'] Mathematics and Physical Sciences 0.7666666666666666\n",
      "['arctic', 'sea', 'ocean', 'storage', 'ice'] Mathematics and Physical Sciences 0.7666666666666666\n",
      "['thermal', 'structural', 'position'] Engineering and IT 0.7912280701754386\n",
      "['engineering', 'engineer', 'test', 'verification', 'technology'] Engineering and IT 0.8596491228070176\n",
      "['signal', 'university', 'department', 'application', 'theory'] Management 0.8333333333333334\n",
      "['optic', 'quantum', 'position'] Engineering and IT 0.7666666666666666\n",
      "['medicine', 'school', 'fellow'] Mathematics and Physical Sciences 0.7638888888888888\n",
      "['cardiac', 'regeneration', 'postdoctoral'] Sales and Marketing 0.7666666666666666\n",
      "['group', 'project'] Management 0.7619047619047619\n",
      "['postdoctoral', 'laboratory', 'cellular', 'researcher', 'position'] Mathematics and Physical Sciences 0.7761904761904761\n",
      "['kilometric', 'development', 'scale', 'global', 'model'] Mathematics and Physical Sciences 0.7592592592592592\n",
      "['engineer', 'intelligence', 'research', 'artificial'] Engineering and IT 0.8070175438596491\n",
      "Similar offers 44\n",
      "Total offers 107\n",
      "41.1214953271028 %\n"
     ]
    }
   ],
   "source": [
    "similarCount = 0\n",
    "\n",
    "for keywords in keywords_per_text:\n",
    "    best_category, similarity_scores = classify_text(keywords, category_map)\n",
    "    if (similarity_scores[best_category] >= 0.75):\n",
    "        similarCount += 1\n",
    "        print (keywords, best_category, similarity_scores[best_category])\n",
    "print (\"Similar offers\", similarCount)\n",
    "print (\"Total offers\", len(keywords_per_text))\n",
    "print (similarCount/len(keywords_per_text) * 100, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
